{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeff Heaton's YouTube Channel\n",
    "* YouTube: [Jeff Heaton/Heatonresearch](https://www.youtube.com/user/HeatonResearch)\n",
    "* GitHub: [Jeff Heaton](https://github.com/jeffheaton)\n",
    "\n",
    "Comparing the Iris classification dataset for TensorFlow/Keras and Pytorch.\n",
    "\n",
    "**TensorFlow/Keras**\n",
    "    \n",
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Read the IRIS dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['species'])\n",
    "species = le.classes_\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct and Train a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 1.1091997623443604\n",
      "Epoch 2, loss: 1.0756523609161377\n",
      "Epoch 3, loss: 1.047439694404602\n",
      "Epoch 4, loss: 0.9993242025375366\n",
      "Epoch 5, loss: 0.942855179309845\n",
      "Epoch 6, loss: 0.9200038313865662\n",
      "Epoch 7, loss: 0.8951579332351685\n",
      "Epoch 8, loss: 0.857270359992981\n",
      "Epoch 9, loss: 0.8332979083061218\n",
      "Epoch 10, loss: 0.8166140913963318\n",
      "Epoch 11, loss: 0.7960920929908752\n",
      "Epoch 12, loss: 0.7781965136528015\n",
      "Epoch 13, loss: 0.7637001872062683\n",
      "Epoch 14, loss: 0.7423258423805237\n",
      "Epoch 15, loss: 0.7234625816345215\n",
      "Epoch 16, loss: 0.704990804195404\n",
      "Epoch 17, loss: 0.6850827932357788\n",
      "Epoch 18, loss: 0.6723629236221313\n",
      "Epoch 19, loss: 0.6545029282569885\n",
      "Epoch 20, loss: 0.6446431875228882\n",
      "Epoch 21, loss: 0.632021427154541\n",
      "Epoch 22, loss: 0.6254460215568542\n",
      "Epoch 23, loss: 0.6166724562644958\n",
      "Epoch 24, loss: 0.6118659973144531\n",
      "Epoch 25, loss: 0.6067811250686646\n",
      "Epoch 26, loss: 0.603151261806488\n",
      "Epoch 27, loss: 0.6004630327224731\n",
      "Epoch 28, loss: 0.5971270203590393\n",
      "Epoch 29, loss: 0.5955595970153809\n",
      "Epoch 30, loss: 0.5925822257995605\n",
      "Epoch 31, loss: 0.5917550921440125\n",
      "Epoch 32, loss: 0.5892060995101929\n",
      "Epoch 33, loss: 0.5884583592414856\n",
      "Epoch 34, loss: 0.5865616202354431\n",
      "Epoch 35, loss: 0.586036205291748\n",
      "Epoch 36, loss: 0.584597647190094\n",
      "Epoch 37, loss: 0.5840724110603333\n",
      "Epoch 38, loss: 0.5829685926437378\n",
      "Epoch 39, loss: 0.5825749039649963\n",
      "Epoch 40, loss: 0.581695020198822\n",
      "Epoch 41, loss: 0.5813168287277222\n",
      "Epoch 42, loss: 0.5805266499519348\n",
      "Epoch 43, loss: 0.5801642537117004\n",
      "Epoch 44, loss: 0.5795419812202454\n",
      "Epoch 45, loss: 0.5793247222900391\n",
      "Epoch 46, loss: 0.5787363052368164\n",
      "Epoch 47, loss: 0.5785734057426453\n",
      "Epoch 48, loss: 0.5781417489051819\n",
      "Epoch 49, loss: 0.5780056715011597\n",
      "Epoch 50, loss: 0.5776534676551819\n",
      "Epoch 51, loss: 0.5775184631347656\n",
      "Epoch 52, loss: 0.5772889256477356\n",
      "Epoch 53, loss: 0.5771061778068542\n",
      "Epoch 54, loss: 0.576949417591095\n",
      "Epoch 55, loss: 0.5767868757247925\n",
      "Epoch 56, loss: 0.5766811966896057\n",
      "Epoch 57, loss: 0.576513946056366\n",
      "Epoch 58, loss: 0.5764375329017639\n",
      "Epoch 59, loss: 0.5762990117073059\n",
      "Epoch 60, loss: 0.5762044191360474\n",
      "Epoch 61, loss: 0.5761093497276306\n",
      "Epoch 62, loss: 0.5760267376899719\n",
      "Epoch 63, loss: 0.5759378671646118\n",
      "Epoch 64, loss: 0.5758455395698547\n",
      "Epoch 65, loss: 0.5757830739021301\n",
      "Epoch 66, loss: 0.5757012367248535\n",
      "Epoch 67, loss: 0.5756456255912781\n",
      "Epoch 68, loss: 0.5755689740180969\n",
      "Epoch 69, loss: 0.5755183100700378\n",
      "Epoch 70, loss: 0.5754655003547668\n",
      "Epoch 71, loss: 0.5753960609436035\n",
      "Epoch 72, loss: 0.5753501057624817\n",
      "Epoch 73, loss: 0.575298011302948\n",
      "Epoch 74, loss: 0.5752478241920471\n",
      "Epoch 75, loss: 0.5751950144767761\n",
      "Epoch 76, loss: 0.5751418471336365\n",
      "Epoch 77, loss: 0.5750946998596191\n",
      "Epoch 78, loss: 0.5750545263290405\n",
      "Epoch 79, loss: 0.5750066637992859\n",
      "Epoch 80, loss: 0.5749662518501282\n",
      "Epoch 81, loss: 0.5749229192733765\n",
      "Epoch 82, loss: 0.5748757719993591\n",
      "Epoch 83, loss: 0.5748357772827148\n",
      "Epoch 84, loss: 0.574791431427002\n",
      "Epoch 85, loss: 0.57476806640625\n",
      "Epoch 86, loss: 0.5747113823890686\n",
      "Epoch 87, loss: 0.5746750235557556\n",
      "Epoch 88, loss: 0.5746370553970337\n",
      "Epoch 89, loss: 0.5746050477027893\n",
      "Epoch 90, loss: 0.5745615363121033\n",
      "Epoch 91, loss: 0.5745192170143127\n",
      "Epoch 92, loss: 0.5744816064834595\n",
      "Epoch 93, loss: 0.57447350025177\n",
      "Epoch 94, loss: 0.5744094252586365\n",
      "Epoch 95, loss: 0.5743696093559265\n",
      "Epoch 96, loss: 0.5743319392204285\n",
      "Epoch 97, loss: 0.5742987394332886\n",
      "Epoch 98, loss: 0.574261486530304\n",
      "Epoch 99, loss: 0.5742210149765015\n",
      "Epoch 100, loss: 0.5741826295852661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_count, out_count):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_count, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, out_count)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "    \n",
    "x_train = Variable(torch.Tensor(x_train).float())\n",
    "x_test = Variable(torch.Tensor(x_test).float())\n",
    "y_train = Variable(torch.LongTensor(y_train))\n",
    "y_test = Variable(torch.LongTensor(y_test))\n",
    "\n",
    "model = Net(x.shape[1],len(species))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model(x_test)\n",
    "_, predict_classes = torch.max(pred, 1)\n",
    "\n",
    "correct = accuracy_score(y_test,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
